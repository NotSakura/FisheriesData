---
title: "Analysing the Fish Hunting Numbers in North Pacific Ocean"
subtitle: "Using Baysian Modeling, to find that number of fish caught has increased"
author: "Shreya Sakura Noskor"
thanks: "Code and data are available at: [https://github.com/NotSakura/FisheriesData.git](https://github.com/NotSakura/FisheriesData.git)."
date: today
date-format: long
abstract: "We analyzed data on fish catches in the North Pacific Ocean using Bayesian modeling. Our analysis shows that the number of fish caught has increased over time. This suggests that fishing activities in the region have intensified. Understanding this trend is important for managing fish populations and ensuring the sustainability of the ocean's resources. This is important as the Pacific is full of different kind of fish like, trout and salmon that are essential in the food chain, but are being overhunted for food and recreational purposes."
format:
  pdf:
    bibliography: references.bib
    documentclass: article
    geometry: margin = 1in
header-includes:
  - \usepackage{float} 
  - \floatplacement{table}{H}
number-sections: true
include-in-header: 
  text:
    \renewcommand{\abstractname}{Abstract}
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(janitor)
library(readxl)
library(dplyr)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(knitr)
library(openxlsx)
```



```{r}
#| echo: false
#| warning: false
#| message: false
data <- read.xlsx('../data/01-raw_data/NPAFC_Catch_Stat-1925-2023.xlsx', sheet = 1) 
colnames(data) <- data[1, ]
data <- data[-1, ]
```


```{r}
#| echo: false
#| warning: false
#| message: false
cleaned_pac2 <- data %>%
  filter(`Data Type` == "Number (000's)", `Whole Country/Province/State` == "Whole country", Species == "Total")  %>%
  select(Country, Species, `Catch Type`, `2022`) %>%
  filter(!is.na(`2022`) & `2022` != 0)

cleaned_pac2 <-cleaned_pac2 %>%
  select(-Species)


cleaned_pac <- data %>%
  filter(Species == "Total", `Data Type` == "Number (000's)", `Reporting Area` == "Whole country") %>%
  filter(!is.na(Country)) %>%
  filter(!is.na(`1925`) & `1925` != 0) %>%
  filter(!is.na(`1946`) & `1946` != 0)


koreadata <- data %>%
  filter(Species == "Total", `Data Type` == "Number (000's)", `Reporting Area` == "Whole country", Country == "Korea") %>%
  filter(!is.na(Country)) 

combined_data <- bind_rows(cleaned_pac, koreadata)

```



```{r}
#| echo: false
#| warning: false
#| message: false

combined_data <- combined_data %>%
  mutate(across(`1925`:`2023`, as.numeric))
koreadata <- koreadata %>%
  mutate(across(`1925`:`2023`, as.numeric))

combined_data <- combined_data  %>%
  select(-`Whole Country/Province/State`, -`Data Type`, -`Reporting Area`, -Species, -`Catch Type`)
koreadata <- koreadata  %>%
  select(-`Whole Country/Province/State`, -`Data Type`, -`Reporting Area`, -Species, -`Catch Type`)

long_data_combined <- combined_data %>%
  pivot_longer(
    cols = starts_with("19") | starts_with("20"),  # Select columns starting with "19" or "20"
    names_to = "Year",
    values_to = "Catch"
  ) %>%
  mutate(Year = as.numeric(Year))

long_data_korea <- koreadata %>%
  pivot_longer(
    cols = starts_with("19") | starts_with("20"),  # Select columns starting with "19" or "20"
    names_to = "Year",
    values_to = "Catch"
  ) %>%
  mutate(Year = as.numeric(Year))
```


# Introduction

Estimand is the number of fishes that were caught by each country, for every year. Or more specifically what the rate was and if they are more likely to be fished for commercial purposes. 

# Data {#sec-data}


## Overview


The data was downloaded from @npafc_statistics and was cleaned using R [@citeR]. The data was read using @openexcel and 
@readxl, while the data was cleaned using @tidy, @tidy, @janitor, @dplyr, @knitr. The data was modeled using @modelsummary, @broom, @rstanarm, and @brms. 

To download the data go to [NPFAC's official data portal](https://www.npafc.org/statistics/) and look for "NPAFC Catch Statistics (updated 28 June 2024)". Click on that link to get the csv file containing all the data. 



## Methodology and Measurement
NPAFC has this data to download from their website. The way they gathered this data was that they are an inter-government organisation so they have access to government data based on how much fish were hunted in the respective countries. The countries in the data include Canada, Russia, Korea, Japan and Unites States of America. The way each of these countries measured this data was that when fish are being caught on international waters and report it to each other. This is strictly enforced, especially after the fall of salmon and trout population in the Pacific, majorly due to environment purposes. 

This paper look at multiple variables. First, variable we look at is Country which are either "Canada", "Russia", "Korea", "Japan", and "United States", all representing the countries that are members of this organization. This data was left unchanged, Next variables we look at is "Whole Country/Province/State", where the instances of these variables may either be Whole country, or the different states or provinces that was fishing and gathered that data. So for example, if the value was British Columbia then the corresponding number of fishes caught reported is the number of fish caught by the province. Throughout our data we filtered for the "Whole country" value, assuming that the numbers in each province and/or state would add up to the number in "Whole country" (which it did). This was because we were more interested in comparing the fishing trends between countries rather then within a country. The next variable is "Reporting Area" which accounts for where the fishes were caught. This was also filtered by "Whole country" due to the previous reasoning. The next variable that we filtered was "Species" which contained "Cherry", "Chinook", "Chum", "Coho", "Pink", "Sockeye", "Steelhead" and "Total". These are all types of salmon except for Steelhead which is a trout and "Total" which represents all the fishes that were hunted. Although there is a lot of interesting information to uncover if we did a deeper analysis on each fish, but, we decided that the best way to compare the fishing trends between countries would be to just look at the total fishes caught. The next variable we used and actually analyse is the "catch type". This tells us whether is the fishes were caught for commercial purposes (caught for profit purposes like selling), sporting purposes (which means they were caught recreationaly) or subsistence purposes (which means they were caught to provide food, not as a profit). The last variable we filtered was "Data Type" which was the unit that these numbers were reported in. There was Numbers in 1000s or Round weight in metric tonne. We chose to filter with numbers in 1000s as the other option was done only by the US, who provided both units.

Thoese were the variables that we filtered or focused on but there is one more variable that is important for this paper; the number of fishes caught. That number in the raw data was provided as the year as a column and the corresponding value as the number of fishes caught. This format meant that when we are creating models or graphs it is very difficult to work with it. And so we actually shifted, rather pivotted the table so that analysis is easier. To pivot the table we created 2 new rows to the dataset, "Year" and "Catch". The year corresponds to the column's title which is the year this data is for and the "catch" refers to the number of fishes that were caught in that year, in that country. This helped significantly with making the models and such. 

## Data Visualization {#sec-graphs}

we make the assumption that the coloumns that say whole country it also include the provinces and different areas number as well. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-long_comb

ggplot(long_data_combined, aes(x = Year, y = Catch, color = Country)) +
  geom_line(size = 1, alpha = 0.7) +  # Line plot with some transparency
  geom_point(size = 2, alpha = 0.8) +  # Points with smaller size
  labs(title = "Catch over Time by Country", x = "Year", y = "Catch") +
  scale_y_continuous(labels = scales::comma) +  # Format y-axis with commas
  theme_minimal() +
  theme(legend.title = element_blank())

```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-korea

ggplot(long_data_korea, aes(x = Year, y = Catch, color = Country)) +
  geom_line(size = 1, alpha = 0.7) +  # Line plot with some transparency
  geom_point(size = 2, alpha = 0.8) +  # Points with smaller size
  labs(title = "Catch over Time by Country", x = "Year", y = "Catch") +
  scale_y_continuous(labels = scales::comma) +  # Format y-axis with commas
  theme_minimal() +
  theme(legend.title = element_blank())

```


```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-total_bar

# Load necessary libraries
library(dplyr)
library(ggplot2)
library(tidyr)

# Create a complete grid of all possible combinations of `Country` and `Catch Type`
complete_data <- expand.grid(
  `Catch Type` = unique(cleaned_pac2$`Catch Type`),
  Country = unique(cleaned_pac2$Country)
)

aggregated_data <- cleaned_pac2 %>%
  group_by(`Catch Type`, Country) %>%
  summarise(
    total_catch = sum(as.numeric(`2022`), na.rm = TRUE), # Convert to numeric
    .groups = "drop"
  )


# Replace "United States" with "US" in the Country variable
full_data <- complete_data %>%
  left_join(aggregated_data, by = c("Catch Type", "Country")) %>%
  mutate(total_catch = ifelse(is.na(total_catch), 0, total_catch)) %>%  # Replace NA with 0 for missing catch data
  mutate(Country = ifelse(Country == "United States", "US", Country))  # Abbreviate United States to US

# Create the plot with the aggregated data and numbers on the bars
ggplot(full_data, aes(x = `Catch Type`, y = total_catch, fill = Country)) +
  geom_bar(stat = "identity", position = "dodge") +  # Bar plot with grouped bars by country
  geom_text(aes(label = paste(Country, ":\n", round(total_catch, 0))),  # Newline between Country and catch number
            position = position_dodge(width = 0.9), 
            vjust = -0.1,  # Adjust vertical position of text
            size = 2) +  # Smaller font size for the numbers
  labs(title = "Catch Data by Country and Catch Type (2022)", 
       x = "Catch Type", 
       y = "Catch Data") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal() +
  theme(legend.title = element_blank())

```



## Outcome and Predictor variables


# Model
Here we model the data in 2 ways. The first way is to model the rate at which the fishes are being caught for any country. And the second model looks at what is the probability that a country is fishing for commercial purposes. 

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`. We also use `brm` package from @brms

## Model Step- Up







```{r}
#| echo: false
#| warning: false
#| message: false
library(tidyr)
library(rstanarm)

#model_formula <- Catch ~ Year + (1 | Country)

#bayesian_model <- stan_glmer(
#  formula = model_formula,
#  data = long_data_combined,
#  family = gaussian(),  # Adjust this if using a different distribution for your data
#  prior = normal(0, 2.5, autoscale = TRUE),
#  prior_intercept = normal(0, 2.5, autoscale = TRUE),
#  seed = 123,
#  adapt_delta = 0.95,
 # cores = 4
#)
#saveRDS(
#  bayesian_model,
#  file = "../models/bayesian_model1.rds"
#)
bayesian_model <-
  readRDS(file = here::here("models/bayesian_model1.rds"))
```





Model 2





```{r}
#| echo: false
#| warning: false
#| message: false

library(brms)

# Specify priors
#priors <- c(
#  set_prior("normal(0, 2.5)", class = "Intercept"),   # Prior for the intercept
#  set_prior("normal(0, 2.5)", class = "sd")           # Prior for the standard deviation of random effects (Country)
#)

#cleaned_pac2$Is_Commercial <- ifelse(cleaned_pac2$`Catch Type` == "Commercial", 1, 0)

# Fit the model using brms
#bayesian_model_commercial_brms <- brm(
#  formula = Is_Commercial ~ (1 | Country),  # Random effect for Country
#  data = cleaned_pac2,
#  family = bernoulli(),                    # Bernoulli family for binary outcomes
#  prior = priors,                          # Use the prior argument here
 # seed = 123
#)

#saveRDS(
#  bayesian_model_commercial_brms,
#  file = "../models/bayesian_model2.rds"
#)

bayesian_model_commercial_brms <-
  readRDS(file = here::here("models/bayesian_model2.rds"))
# Extract random effects using brms
ranef_bayesian_model_commercial_brms <- ranef(bayesian_model_commercial_brms)
```




the base line probability of having a country that is fishing for commercial purpose is log of 0.838 which is 69.8%. which means that there is 69.8% probability that the country is fishing for commercial purposes, without even knowing the country. 


```{r}
#| echo: false
#| warning: false
#| message: false
# Extract random effects for Country
random_effects_df <- as.data.frame(ranef_bayesian_model_commercial_brms$Country)

# Check the column names (they are already known: "Estimate.Intercept", etc.)
names(random_effects_df)

# Now, plot the distribution of the random intercepts for Country
library(ggplot2)

ggplot(random_effects_df, aes(x = Estimate.Intercept)) + 
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Random Intercepts for Country",
       x = "Random Intercept (Country)",
       y = "Frequency") +
  theme_minimal()


```



```{r}
#| echo: false
#| warning: false
#| message: false
# Extract random effects for Country
random_effects_df <- as.data.frame(ranef(bayesian_model_commercial_brms)$Country)

# Add the country names (indexing row names)
random_effects_df$Country <- rownames(random_effects_df)

# Check the structure to confirm the data is correct
head(random_effects_df)

# Extract the fixed intercept (the global intercept)
fixed_intercept <- fixef(bayesian_model_commercial_brms)[1]  # First element corresponds to the intercept

# Add the random intercepts to the fixed intercept to get the log-odds
random_effects_df$log_odds <- fixed_intercept + random_effects_df$Estimate.Intercept

# Compute predicted probabilities using the log-odds
random_effects_df$predicted_prob <- 1 / (1 + exp(-random_effects_df$log_odds))

# Plot the predicted probabilities for Commercial catches across countries
library(ggplot2)

ggplot(random_effects_df, aes(x = Country, y = predicted_prob)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") +
  labs(title = "Predicted Probability of Commercial Catch by Country",
       x = "Country",
       y = "Predicted Probability") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate country names for readability
  theme_minimal()

```




### Model justification



# Results


## Model Results

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model1
#| tbl-cap: "baysian model summary for predicting the rate of fishes being caught"

modelsummary::modelsummary(
  list(
    "First model" = bayesian_model
  ),
  statistic = "mad",
  fmt = 2
)
```


```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-model2
#| tbl-cap: "baysian model summary for predicting the probability of country fishing for commercial purposes."

modelsummary::modelsummary(
  list(
    "Second model" = bayesian_model_commercial_brms
  ),
  statistic = "mad",
  fmt = 2
)
```



# Discussion

## Weaknesses and next steps
Korea didn't report data until 1969 so they are left out of the first model in general. 

\newpage

\appendix

# Appendix 1


# Appendix 2 (datasheet)

1. For what purpose was the dataset created?
The dataset was originally created by North Pacific Anadormous Fish Commission [@npafc_statistics] created this dataset to see how much fishing of trout and salmon was done in international waters. They strictly prohibits mass fishing of these highly demanded fishes and hense the dataset. We use the dataset to analyse the number of these fishes caught and see if there is a reason for NPAFC to be worried, and if there is a solution to this. 

2.What do the instances that comprise the dataset represent (for example, documents, photos, people, countries)?
The instances of these data is either numeric or catagorical. Thee first couple of columns tells you the country the data is from, where the fishes were hunted as well as getting to specific regions. Why they were hunted and what the unit were, was also in the data set. The majority of the dataset is numbers expressing how much fish was hunted, either in thousands or tonnes. 

3.Is any information missing from individual instances?
There are several instances of data missing. Most are from the number of fishes column as some of the data goes back to 1925 but, not all of them so, there are some rows of data where the total number of fishes collected in 1928, for example, is not present. 

4. How was the data associated with each instance acquired? Was the data directly observable (for example, raw text, movie ratings), reported by subjects (for example, survey responses), or indirectly inferred/ derived from other data (for example, part-of-speech tags, model-based guesses for age or language)?

This dataset was reported by the subjects of each country. Meaning this organisation asked the government of Canada, US, Korea, Russia and Japan, send in the numbers and they compiled this data. 


# References
